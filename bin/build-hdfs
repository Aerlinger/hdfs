#!/bin/bash

HADOOP_DIR=hadoop-2.3.0-cdh5.1.0
HADOOP_ZIP=$HADOOP_DIR.tar.gz
HADOOP_URL=http://archive.cloudera.com/cdh5/cdh/5/$HADOOP_ZIP
DIST=hdfs-mesos-0.0.2

# Remove cached binaries and exit
if [ "$1" == "clean" ]; then
    rm -f $HADOOP_ZIP
    rm -rf $HADOOP_DIR
    rm -rf native
    rm -rf $DIST
    rm -f $DIST.tgz
    exit 0
fi

# Download hadoop binary
if [ ! -f $HADOOP_ZIP ]; then
    echo "Downloading $HADOOP_URL"
    wget $HADOOP_URL || exit
else
    echo "($HADOOP_ZIP already exists, skipping dl)"
fi

# Extract hadoop, remove cruft
if [ ! -d $HADOOP_DIR ]; then
    echo "Extracting $HADOOP_ZIP"
    tar xf $HADOOP_ZIP

    # Remove unneeded files
    cd $HADOOP_DIR
    rm -rf cloudera
    rm -rf examples*
    rm -rf src
    rm -rf share/hadoop/mapreduce*
    rm -rf share/hadoop/yarn
    rm -rf share/doc
    rm -rf etc/hadoop-mapreduce*
    cd ..
else
    echo "($HADOOP_DIR already exists, skipping extract)"
fi

# Get native libraries
if [ ! -d "native" ]; then
    echo "Downloading and unpacking native libs"
    wget https://github.com/cloudera/Impala/archive/cdh5-1.4_5.1.0.zip || exit
    unzip -q cdh5-1.4_5.1.0.zip
    mkdir -p native
    cp Impala-cdh5-1.4_5.1.0/thirdparty/hadoop-2.3.0-cdh5.1.0/lib/native/lib* native
    rm -rf cdh5-1* Impala*
else
    echo "(native libs already exist, skipping dl)"
fi

# Copy to dist
if [ ! -d $DIST ]; then
    echo "Creating new $DIST dist folder"
    mkdir -p $DIST
    cp -R $HADOOP_DIR/* $DIST
else
    echo "($DIST already exists, skipping create)"
fi

echo "Copying build output into $DIST"
cd $DIST
cp ../bin/* bin/
cp ../target/*-uber.jar lib/
cp ../conf/* etc/hadoop/
cp ../native/* lib/native
cd ..

# Compress tarball
echo "Compressing to $DIST.tgz"
tar czf $DIST.tgz $DIST
